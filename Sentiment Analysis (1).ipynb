{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impressed-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "disabled-second",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\HP\\Desktop\\datasets\\Reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-blogger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = {'ProductId', 'UserId', 'ProfileName','HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "visible-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Score'] = ['Positive' if x>3 else('Neutral' if x == 3 else 'Negative') for x in data['Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "present-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "signed-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data1.iloc[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "early-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "irish-purpose",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "data_test.drop(columns = {'Id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "liquid-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "driving-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "final_corpus = []\n",
    "for i in range(len(data_test)):\n",
    "    pattern = re.sub(r'[^\\w\\s]', '', data_test['Text'][i])    \n",
    "    \n",
    "    pattern = pattern.lower()\n",
    "    \n",
    "    pattern = word_tokenize(pattern)\n",
    "    \n",
    "    pattern = [ps.stem(word.lower()) for word in pattern if word not in stopword] \n",
    "    \n",
    "    pattern = ' '.join(pattern)\n",
    "    final_corpus.append(pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-lease",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-vehicle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "original-sellers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "collected-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "X = cv.fit_transform(final_corpus).toarray()\n",
    "y=data_test.iloc[:,0].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "delayed-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "extreme-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1=LogisticRegression()\n",
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "interstate-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model1=model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "transsexual-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.40      0.19      0.26        31\n",
      "     Neutral       0.00      0.00      0.00        11\n",
      "    Positive       0.82      0.94      0.87       158\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.41      0.38      0.38       200\n",
      "weighted avg       0.71      0.77      0.73       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "greek-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment = pd.read_excel(r'C:\\Users\\HP\\Desktop\\nuvoretail_sentiment_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intended-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "standing-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_data = sentiment['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "entitled-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_corpus = []\n",
    "#for i in range(len(sample_data)):\n",
    " #   review = re.sub(r'[^\\w\\s]', '', sample_data[i])    \n",
    "    \n",
    " #   review = review.lower()\n",
    "    \n",
    " #   review = word_tokenize(review)\n",
    "    \n",
    " #   review = [ps.stem(word.lower()) for word in review if word not in stopword] \n",
    "    \n",
    " #   review = ' '.join(review)\n",
    " #   test_corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleased-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which columns are expected by the model, but not exist in the inference dataframe\n",
    "#not_existing_cols = [c for c in X.columns.tolist() if c not in x_sample]\n",
    "# add this columns to the data frame\n",
    "#x_sample = x_sample.reindex(x_sample.columns.tolist() + not_existing_cols, axis=1)\n",
    "# new columns dont have values, replace null by 0\n",
    "#x_sample.fillna(0, inplace = True)\n",
    "# use the original X structure as mask for the new inference dataframe\n",
    "#x_sample = x_sample[X.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "worth-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x_sample = cv.fit_transform(test_corpus).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "studied-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_model = model1.predict(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hybrid-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFIDF  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "recreational-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(final_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "destroyed-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data_test.iloc[:,0].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "regulation-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train,X1_test,y1_train,y1_test=train_test_split(tfidf,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "italian-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=LogisticRegression()\n",
    "model2.fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "psychological-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model_tfdif = model2.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fifteen-details",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.06      0.12        31\n",
      "     Neutral       0.00      0.00      0.00        11\n",
      "    Positive       0.80      1.00      0.89       158\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.60      0.35      0.34       200\n",
      "weighted avg       0.79      0.80      0.72       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1_test,y_model_tfdif))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-nature",
   "metadata": {},
   "source": [
    "## Junk, Don't read below this ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-threshold",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-penalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-pride",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-queens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ranking-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_tfidf = tfidf_vectorizer.fit_transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ambient-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model_tfdif = model2.predict(x_sample_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "present-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model_tfdif_df = pd.DataFrame(sample_model_tfdif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "roman-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   Positive\n",
       "1   Positive\n",
       "2   Positive\n",
       "3   Positive\n",
       "4   Positive\n",
       "5   Positive\n",
       "6   Positive\n",
       "7   Positive\n",
       "8   Positive\n",
       "9   Positive\n",
       "10  Positive\n",
       "11  Positive\n",
       "12  Positive\n",
       "13  Positive\n",
       "14  Positive\n",
       "15  Positive\n",
       "16  Negative\n",
       "17  Positive\n",
       "18  Positive\n",
       "19  Negative"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model_tfdif_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "intermediate-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([sentiment, sample_model_tfdif_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "suspected-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.rename(columns = {0: 'Sentiment'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "pressed-sleeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>Column1</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>comment_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Reviewed in India on 28 January 2021</td>\n",
       "      <td>Must buy</td>\n",
       "      <td>\\n  Best quality\\n</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>2</td>\n",
       "      <td>Reviewed in India on 26 January 2021</td>\n",
       "      <td>Just taste splendid</td>\n",
       "      <td>\\n  It's test with without warm milk is just a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>3</td>\n",
       "      <td>Reviewed in India on 23 January 2021</td>\n",
       "      <td>Good for the ones who have a sweet tooth.</td>\n",
       "      <td>\\n  Too sweet.\\n</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>4</td>\n",
       "      <td>Reviewed in India on 21 January 2021</td>\n",
       "      <td>Don't buy it</td>\n",
       "      <td>\\n  Very bad quality it's useless better to bu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>5</td>\n",
       "      <td>Reviewed in India on 19 January 2021</td>\n",
       "      <td>Taste is good</td>\n",
       "      <td>\\n  Good .but when opened its was half of the ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_stamp  Column1                          comment_date  \\\n",
       "0   01-02-21        1  Reviewed in India on 28 January 2021   \n",
       "1   01-02-21        2  Reviewed in India on 26 January 2021   \n",
       "2   01-02-21        3  Reviewed in India on 23 January 2021   \n",
       "3   01-02-21        4  Reviewed in India on 21 January 2021   \n",
       "4   01-02-21        5  Reviewed in India on 19 January 2021   \n",
       "\n",
       "                               comment_title  \\\n",
       "0                                   Must buy   \n",
       "1                        Just taste splendid   \n",
       "2  Good for the ones who have a sweet tooth.   \n",
       "3                               Don't buy it   \n",
       "4                              Taste is good   \n",
       "\n",
       "                                             comment Sentiment  \n",
       "0                                 \\n  Best quality\\n  Positive  \n",
       "1  \\n  It's test with without warm milk is just a...  Positive  \n",
       "2                                   \\n  Too sweet.\\n  Positive  \n",
       "3  \\n  Very bad quality it's useless better to bu...  Positive  \n",
       "4  \\n  Good .but when opened its was half of the ...  Positive  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "present-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_excel(r'C:\\Users\\HP\\Desktop\\sentiment_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-circle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
