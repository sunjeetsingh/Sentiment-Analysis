{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impressed-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "disabled-second",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\HP\\Desktop\\datasets\\Reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-blogger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = {'ProductId', 'UserId', 'ProfileName','HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "visible-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Score'] = ['Positive' if x>3 else('Neutral' if x == 3 else 'Negative') for x in data['Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "present-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "signed-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data1.iloc[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "early-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "irish-purpose",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "data_test.drop(columns = {'Id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "liquid-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "driving-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "final_corpus = []\n",
    "for i in range(len(data_test)):\n",
    "    pattern = re.sub(r'[^\\w\\s]', '', data_test['Text'][i])    \n",
    "    \n",
    "    pattern = pattern.lower()\n",
    "    \n",
    "    pattern = word_tokenize(pattern)\n",
    "    \n",
    "    pattern = [ps.stem(word.lower()) for word in pattern if word not in stopword] \n",
    "    \n",
    "    pattern = ' '.join(pattern)\n",
    "    final_corpus.append(pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-lease",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-vehicle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "original-sellers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "collected-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "X = cv.fit_transform(final_corpus).toarray()\n",
    "y=data_test.iloc[:,0].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "delayed-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "extreme-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1=LogisticRegression()\n",
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "interstate-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model1=model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "transsexual-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.40      0.19      0.26        31\n",
      "     Neutral       0.00      0.00      0.00        11\n",
      "    Positive       0.82      0.94      0.87       158\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.41      0.38      0.38       200\n",
      "weighted avg       0.71      0.77      0.73       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "greek-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.read_excel(r'C:\\Users\\HP\\Desktop\\nuvoretail_sentiment_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "intended-economics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>Column1</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>comment_title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Reviewed in India on 28 January 2021</td>\n",
       "      <td>Must buy</td>\n",
       "      <td>\\n  Best quality\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>2</td>\n",
       "      <td>Reviewed in India on 26 January 2021</td>\n",
       "      <td>Just taste splendid</td>\n",
       "      <td>\\n  It's test with without warm milk is just a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>3</td>\n",
       "      <td>Reviewed in India on 23 January 2021</td>\n",
       "      <td>Good for the ones who have a sweet tooth.</td>\n",
       "      <td>\\n  Too sweet.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>4</td>\n",
       "      <td>Reviewed in India on 21 January 2021</td>\n",
       "      <td>Don't buy it</td>\n",
       "      <td>\\n  Very bad quality it's useless better to bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>5</td>\n",
       "      <td>Reviewed in India on 19 January 2021</td>\n",
       "      <td>Taste is good</td>\n",
       "      <td>\\n  Good .but when opened its was half of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>7013</td>\n",
       "      <td>Reviewed in India on 1 January 2021</td>\n",
       "      <td>Delicious, healthy &amp; quick to cook!</td>\n",
       "      <td>\\n  Kelloggs Upma tastes very delicious with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>7014</td>\n",
       "      <td>Reviewed in India on 25 December 2020</td>\n",
       "      <td>All in one - Taste, Health and Ease of prepara...</td>\n",
       "      <td>\\n  I am always in a jiffy in the morning and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>7015</td>\n",
       "      <td>Reviewed in India on 24 December 2020</td>\n",
       "      <td>Home like taste</td>\n",
       "      <td>\\n  Finally an instant upma that tastes like w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>7016</td>\n",
       "      <td>Reviewed in India on 7 December 2020</td>\n",
       "      <td>Terrible</td>\n",
       "      <td>\\n  Very very weird taste the moment you put t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>7017</td>\n",
       "      <td>Reviewed in India on 4 December 2020</td>\n",
       "      <td>Yummy</td>\n",
       "      <td>\\n  This is super yummy. Can be made faster th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7017 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time_stamp  Column1                           comment_date  \\\n",
       "0      01-02-21        1   Reviewed in India on 28 January 2021   \n",
       "1      01-02-21        2   Reviewed in India on 26 January 2021   \n",
       "2      01-02-21        3   Reviewed in India on 23 January 2021   \n",
       "3      01-02-21        4   Reviewed in India on 21 January 2021   \n",
       "4      01-02-21        5   Reviewed in India on 19 January 2021   \n",
       "...         ...      ...                                    ...   \n",
       "7012   01-02-21     7013    Reviewed in India on 1 January 2021   \n",
       "7013   01-02-21     7014  Reviewed in India on 25 December 2020   \n",
       "7014   01-02-21     7015  Reviewed in India on 24 December 2020   \n",
       "7015   01-02-21     7016   Reviewed in India on 7 December 2020   \n",
       "7016   01-02-21     7017   Reviewed in India on 4 December 2020   \n",
       "\n",
       "                                          comment_title  \\\n",
       "0                                              Must buy   \n",
       "1                                   Just taste splendid   \n",
       "2             Good for the ones who have a sweet tooth.   \n",
       "3                                          Don't buy it   \n",
       "4                                         Taste is good   \n",
       "...                                                 ...   \n",
       "7012                Delicious, healthy & quick to cook!   \n",
       "7013  All in one - Taste, Health and Ease of prepara...   \n",
       "7014                                    Home like taste   \n",
       "7015                                           Terrible   \n",
       "7016                                              Yummy   \n",
       "\n",
       "                                                comment  \n",
       "0                                    \\n  Best quality\\n  \n",
       "1     \\n  It's test with without warm milk is just a...  \n",
       "2                                      \\n  Too sweet.\\n  \n",
       "3     \\n  Very bad quality it's useless better to bu...  \n",
       "4     \\n  Good .but when opened its was half of the ...  \n",
       "...                                                 ...  \n",
       "7012  \\n  Kelloggs Upma tastes very delicious with a...  \n",
       "7013  \\n  I am always in a jiffy in the morning and ...  \n",
       "7014  \\n  Finally an instant upma that tastes like w...  \n",
       "7015  \\n  Very very weird taste the moment you put t...  \n",
       "7016  \\n  This is super yummy. Can be made faster th...  \n",
       "\n",
       "[7017 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "standing-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sentiment['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "adult-massage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      \\n  Best quality\\n\n",
       "1       \\n  It's test with without warm milk is just a...\n",
       "2                                        \\n  Too sweet.\\n\n",
       "3       \\n  Very bad quality it's useless better to bu...\n",
       "4       \\n  Good .but when opened its was half of the ...\n",
       "                              ...                        \n",
       "7012    \\n  Kelloggs Upma tastes very delicious with a...\n",
       "7013    \\n  I am always in a jiffy in the morning and ...\n",
       "7014    \\n  Finally an instant upma that tastes like w...\n",
       "7015    \\n  Very very weird taste the moment you put t...\n",
       "7016    \\n  This is super yummy. Can be made faster th...\n",
       "Name: comment, Length: 7017, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "entitled-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = []\n",
    "for i in range(len(sample_data)):\n",
    "    review = re.sub(r'[^\\w\\s]', '', sample_data[i])    \n",
    "    \n",
    "    review = review.lower()\n",
    "    \n",
    "    review = word_tokenize(review)\n",
    "    \n",
    "    review = [ps.stem(word.lower()) for word in review if word not in stopword] \n",
    "    \n",
    "    review = ' '.join(review)\n",
    "    test_corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "pleased-mustang",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-ca3e1c793abd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check which columns are expected by the model, but not exist in the inference dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnot_existing_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# add this columns to the data frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnot_existing_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# new columns dont have values, replace null by 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# check which columns are expected by the model, but not exist in the inference dataframe\n",
    "not_existing_cols = [c for c in X.columns.tolist() if c not in x_sample]\n",
    "# add this columns to the data frame\n",
    "x_sample = x_sample.reindex(x_sample.columns.tolist() + not_existing_cols, axis=1)\n",
    "# new columns dont have values, replace null by 0\n",
    "x_sample.fillna(0, inplace = True)\n",
    "# use the original X structure as mask for the new inference dataframe\n",
    "x_sample = x_sample[X.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "worth-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_sample = cv.fit_transform(test_corpus).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "studied-recovery",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 2209 features per sample; expecting 5179",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-11920d2f56e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2209 features per sample; expecting 5179"
     ]
    }
   ],
   "source": [
    "sample_model = model1.predict(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "hybrid-determination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7017, 2209)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFIDF  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "recreational-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(final_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "destroyed-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data_test.iloc[:,0].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "regulation-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train,X1_test,y1_train,y1_test=train_test_split(tfidf,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "italian-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=LogisticRegression()\n",
    "model2.fit(X1_train,y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "psychological-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model_tfdif = model2.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fifteen-details",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.06      0.12        31\n",
      "     Neutral       0.00      0.00      0.00        11\n",
      "    Positive       0.80      1.00      0.89       158\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.60      0.35      0.34       200\n",
      "weighted avg       0.79      0.80      0.72       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1_test,y_model_tfdif))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-nature",
   "metadata": {},
   "source": [
    "## Junk, Don't read below this ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-threshold",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-penalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-pride",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-queens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ranking-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_tfidf = tfidf_vectorizer.fit_transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ambient-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model_tfdif = model2.predict(x_sample_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "present-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model_tfdif_df = pd.DataFrame(sample_model_tfdif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "roman-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   Positive\n",
       "1   Positive\n",
       "2   Positive\n",
       "3   Positive\n",
       "4   Positive\n",
       "5   Positive\n",
       "6   Positive\n",
       "7   Positive\n",
       "8   Positive\n",
       "9   Positive\n",
       "10  Positive\n",
       "11  Positive\n",
       "12  Positive\n",
       "13  Positive\n",
       "14  Positive\n",
       "15  Positive\n",
       "16  Negative\n",
       "17  Positive\n",
       "18  Positive\n",
       "19  Negative"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model_tfdif_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "intermediate-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([sentiment, sample_model_tfdif_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "suspected-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.rename(columns = {0: 'Sentiment'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "pressed-sleeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>Column1</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>comment_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Reviewed in India on 28 January 2021</td>\n",
       "      <td>Must buy</td>\n",
       "      <td>\\n  Best quality\\n</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>2</td>\n",
       "      <td>Reviewed in India on 26 January 2021</td>\n",
       "      <td>Just taste splendid</td>\n",
       "      <td>\\n  It's test with without warm milk is just a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>3</td>\n",
       "      <td>Reviewed in India on 23 January 2021</td>\n",
       "      <td>Good for the ones who have a sweet tooth.</td>\n",
       "      <td>\\n  Too sweet.\\n</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>4</td>\n",
       "      <td>Reviewed in India on 21 January 2021</td>\n",
       "      <td>Don't buy it</td>\n",
       "      <td>\\n  Very bad quality it's useless better to bu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-02-21</td>\n",
       "      <td>5</td>\n",
       "      <td>Reviewed in India on 19 January 2021</td>\n",
       "      <td>Taste is good</td>\n",
       "      <td>\\n  Good .but when opened its was half of the ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_stamp  Column1                          comment_date  \\\n",
       "0   01-02-21        1  Reviewed in India on 28 January 2021   \n",
       "1   01-02-21        2  Reviewed in India on 26 January 2021   \n",
       "2   01-02-21        3  Reviewed in India on 23 January 2021   \n",
       "3   01-02-21        4  Reviewed in India on 21 January 2021   \n",
       "4   01-02-21        5  Reviewed in India on 19 January 2021   \n",
       "\n",
       "                               comment_title  \\\n",
       "0                                   Must buy   \n",
       "1                        Just taste splendid   \n",
       "2  Good for the ones who have a sweet tooth.   \n",
       "3                               Don't buy it   \n",
       "4                              Taste is good   \n",
       "\n",
       "                                             comment Sentiment  \n",
       "0                                 \\n  Best quality\\n  Positive  \n",
       "1  \\n  It's test with without warm milk is just a...  Positive  \n",
       "2                                   \\n  Too sweet.\\n  Positive  \n",
       "3  \\n  Very bad quality it's useless better to bu...  Positive  \n",
       "4  \\n  Good .but when opened its was half of the ...  Positive  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "present-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_excel(r'C:\\Users\\HP\\Desktop\\sentiment_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-circle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
